

## url
在浏览器搜索特殊内容, 如果会被服务器编码成特殊类型, 比如`%2F`等。
- 因为在url中，%\\&等符号是特殊字符，所以防止搜索内容对其产生影响，对所有搜索内容做特殊处理

## http

    |请求方法|请求的url|请求的http版本|
    |http各种属性，（name：value）|（多行）
    |空行|
    |请求正文(可以没有)|
- 我可以读取完整的一行
- while(读取完成的一行), 所有的请求行+请求报头全部读完, 直到读到空行
- 报头有一个属性: Content-Length: XXX正文长度,
- 解析出来的内容, 再根据内容长度, 读取正文即可

>- telnet [ip] [端口] 向指定地址发送请求
>- Content-Type对照表可以查看Content-Type属性

一个用户看到的网页结果, 可能有很多的资源组成。所以，要获取一张完整的网页效果，我们的浏览器一定会发起多次http请求

### GET和POST提取参数
- GET通过url传递参数`http://ip:port/XXX/YY?name=value&name2=value2`
- POST提交参数通过http请求的正文提交参数

>- POST方法通过正文提交参数，所以一般用户看不到，私密性更好`私密性！=安全性`
>- GET方法不私密\
>无论是GET还是POST方法, 都是不安全的! 要谈安全, 必须加密
>- 通过URL传参, 注定不能太大
>- 但是POST方法, 通过正文, 正文可以很大, 甚至可以是其他东西

### 重定向
临时重定向, 返回3XX, 和一个新URL, 让用户访问新的网站

永久重定向, 一般作用于书签, 底层更新书签的url

### 长连接
http网页中可能包含多个元素，如果频繁发起http请求，http是基于tcp的，tcp是面向连接的，就会产生频繁创建连接的问题

需要client和server都要支持，长连接，建立好一条连接，获取一大份资源的时候，通过同一条链接完成
`Connection: keep-alive`
### http周边会话保持
严格意义上不是http天然具备的, 是后面使用发现需要的
>http协议是无状态的，但是用户需要，因为用户查看新的网页是常规操作，如果发生网页跳转，那么新的网页也就无法识别是哪一个用户了，为了让用户一经登录，可以在整个网站按照自己的身份进行随意访问

>浏览器把用户输入的用户名&密码保存起来\
保存叫做cookie技术`cookie文件级别和内存级别`\
往后只要访问同一个网站，浏览器就会自动推送历史保留信息

>凡是与网页访问有权限要求的网页,在被获取前,全部都要判断!!!

>- 旧方案, 将用户用户名和密码保存在本地cookie文件中
>- 新方案, 将用户的用户名和密码保存在server中的session文件中, 并为其做唯一标识, session id。client的cookie保存session id\
    首次连接用户端输入账户和密码, 服务器返回session id, 以后client就用session id做访问
### 基本工具
postman, fiddler
>- postman, 不是抓包工具, 是模拟客户端--浏览器的行为
>- fiddler, 是一个抓包工具, http工具 -- 调试

>fiddler就是在client和server之间传递发送数据和接收数据
### https
也就是在应用层中添加一个加密协议, 并添加传输层的端口`443`

